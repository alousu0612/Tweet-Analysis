---
header-includes:
- \usepackage{fontspec} # 使用 fontspec package
- \usepackage{ctex}    # 使用 xeCJK package
- \setCJKmainfont{標楷體} # 指定主要的字型，windows 使用者可用「標楷體」、「新細明體」，或是依照您安裝的字型名稱輸入
output: 
  pdf_document: 
    keep_tex: yes # 保留 tex 檔，萬一出了問題，可以手動檢查並重新編譯
    latex_engine: xelatex # latex 引擎設定為 xelatex
    toc: true
    number_sections: true
indent: true
fontsize: 12pt
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tm) # for NLP
library(RWeka)
library(plyr) #  for pre-processing 
library(tidyverse) # for pre-processing and visualisation
library(reshape2) # for melt function
library(e1071) # for Naive Bayes classifier
library(glmnet) # for Logistic Regression classifier
library(randomForest) # for Random Forest classifier
library(caret)
library(ROCit)
library(gmodels)
library(factoextra)
library(irlba) # singular values Decomp.
library(grid)
library(png)
library(tidyverse)
library(stringi)
library(tm)
library(irlba)
library(gridExtra)
library(caret)
library(NbClust)
library(caretEnsemble)
library(wordcloud)
```

# Program Code

## EDA

### Data
```{r, eval=FALSE, message=FALSE, warnings=FALSE}
### Loading Buzzfeed datasets
tweets_train <- read.csv('./data/disastertweets/train.csv',
                         stringsAsFactor = F, na.strings = c(""))
tweets_test <- read.csv('./data/disastertweets/test.csv',
                        stringsAsFactor = F, na.strings = c(""))
```

```{r, eval=FALSE, message=FALSE, warnings=FALSE}
dim(tweets_test)
dim(tweets_train)
```

```{r, eval=FALSE, message=FALSE, warnings=FALSE}
### Pre- processing / Feature Engineering
tweets_complete <- bind_rows(tweets_train, tweets_test)
```

```{r, eval=FALSE, message=FALSE, warnings=FALSE}
# Train data
tweets_train  <- tweets_train %>% 
    mutate(
        target = as.factor(case_when(target == 0 ~ 'No',
                                     target == 1 ~ 'Yes'))
    )%>%
    dplyr::select(everything())

# Complete data
tweets_complete <- tweets_complete %>% 
    mutate(
        target = as.factor(case_when(target == 0 ~ 'No',
                                     target == 1 ~ 'Yes'))
    )%>%
    dplyr::select(everything())
```

```{r, eval=FALSE, message=FALSE, warnings=FALSE}
head(unique(tweets_complete$keyword))
head(unique(tweets_complete$location))
```

```{r, eval=FALSE, message=FALSE, warnings=FALSE}
missing_data <- colSums(sapply(tweets_train, is.na))
missing_data
```

```{r, eval=FALSE, message=FALSE, warnings=FALSE}
tweets_train$TextLength <- sapply(tweets_train$text, str_length)

tweets_complete$TextLength <- sapply(tweets_complete$text, str_length)
summary(tweets_complete$TextLength)
```

### Text Features Analysis - text length

```{r, eval=FALSE, message=FALSE, warnings=FALSE}
# perform t-test
t.test(tweets_train[tweets_train$target == "Yes",]$TextLength,
       tweets_train[tweets_train$target == "No",]$TextLength)

# plotting histogram of text length
ggplot(tweets_train ,aes(x=TextLength, fill=target)) +
    ggtitle('Density distribuiton of text length for Tweets') +
    geom_density(alpha=0.5) +
    guides(fill=guide_legend(title='reliability')) + 
    labs(x='Text length', y='Density')
   
```


### Text Cleansing

```{r, eval=FALSE, message=FALSE, warnings=FALSE}
## Unigrams
removeURL <- function(x) {
    gsub("http[^[:space:]]*", "", x)
}

removeUser <- function(x){
    gsub("@[^[:space:]]*", "", x)
}

removeNumPunct <- function(x){
    gsub("[^[:alpha:][:space:]]*", "", x) 
} 

removeSingle <- function(x){
    gsub(" . ", " ", x)   
}

clean_specialChar <- function(x){
    gsub("…|⋆|–|‹|”|“|‘|’",'',x)
}

StopWords <- c((stopwords('english')), 
                 c("really", "tweets", "saw", "just", "feel", "may", "us",
                   "rt", "every", "one","amp", "like", "will", "got", "new",
                   "can", "still", "back", "top", "much","near", "im",
                   "see", "via", "get", "now", "come", "oil", "let", "god",
                   "want", "pm", "last", "hope", "since", "everyone",
                   "food","content", "always", "th", "full", "found",
                   "dont", "look", "cant", "mh", "lol", "set", "old",
                   "service", "city", "home", "live", "night", "news",
                   "say", "video", "people", "ill", "way",  "please",
                   "years", "take", "homes", "read", "man", "next", "cross", 
                   "boy", "bad", "ass", "love", "news"))

preprocess_corpus <- function(corpus, stemming=TRUE){
    corpus <- Corpus(VectorSource(corpus))
    
    corpus <- tm_map(corpus, content_transformer(removeURL))
    corpus <- tm_map(corpus, content_transformer(removeUser))

    corpus <- tm_map(corpus, content_transformer(stri_trans_tolower))
    corpus <- tm_map(corpus, content_transformer(removeNumPunct))
    #corpus <- tm_map(corpus, removeNumbers)
    #corpus <- tm_map(corpus, removePunctuation)
    corpus <- tm_map(corpus, removeWords, StopWords)
    corpus <- tm_map(corpus, function(x) iconv(x, "latin1", "ASCII", sub=""))
    corpus <- tm_map(corpus, removeSingle)
    if(stemming==TRUE){
      corpus <- tm_map(corpus, stemDocument)
    }
    corpus <- tm_map(corpus, stripWhitespace)
    
    dtM <- DocumentTermMatrix(corpus)
    return(dtM)
}
```

```{r, eval=FALSE, message=FALSE, warnings=FALSE}
## Bigrams
bigramTokenizer <- function(x){
    unlist(lapply(ngrams(words(x), 2), paste, collapse = " "),
           use.names = FALSE)
}

bigram_corpus <- function(corpus, minIgnore=.01, maxIgnore=.80){
    corpus <- VCorpus(VectorSource(corpus))
    
    corpus <- tm_map(corpus, content_transformer(stri_trans_tolower))
    corpus <- tm_map(corpus, removeWords, StopWords)
    
    corpus_len <- length(corpus)
    minDocFreq <- corpus_len * minIgnore
    maxDocFreq <- corpus_len * maxIgnore
    
    bigM <- DocumentTermMatrix(corpus,
                               control=list(tokenize=bigramTokenizer,
                                            removePunctuation=TRUE,
                                            stemming = FALSE,
                                            global=c(minDocFreq, maxDocFreq)))
    return(bigM)
}
```

```{r, eval=FALSE, message=FALSE, warnings=FALSE}
### Word Frequency - find top n representative words (unigrams)
top_unigram <- function(dtMatrix, type, top_n=15){
    dtM_df <- data.frame(as.matrix(dtMatrix))
    
    chi2Vals <- apply(dtM_df, 2, function(x){
        chisq.test(as.numeric(x), type)$statistic
    })
    words_subset <- names(sort(chi2Vals, decreasing=TRUE))[1:top_n]
    
    dtM_df$type <- type
    freq_df <- dtM_df %>% 
        group_by(type) %>% 
        summarise_each(funs(sum))
    top_n <- freq_df[, c(words_subset, 'type')]
    return(top_n)
}
```

```{r, eval=FALSE, message=FALSE, warnings=FALSE}
### Word Frequency - find top n representative words (bigrams)
top_bigram <- function(dtMatrix, type, top_n=20){
    dtMatrix <- as.matrix(dtMatrix)
    bigrams <- names(sort(colSums(dtMatrix), decreasing=TRUE))
    
    top_bigram_list <- c()
    for(bigram in bigrams){
        unigrams <- strsplit(bigram," ")
        removal <- c(unlist(stopwords('en')))
        if(!(unigrams[[1]][1] %in% removal | unigrams[[1]][2]  %in% removal)){
            top_bigram_list <- c(top_bigram_list, bigram)
        }
        if (length(top_bigram_list) ==top_n){
            break
        }
    }
    
    dtM_bigram <- data.frame(dtMatrix[, intersect(colnames(dtMatrix),
                                                  top_bigram_list)])
    dtM_bigram$type <- type
    freq_df <- dtM_bigram %>%
        group_by(type) %>%
        summarise_each(funs(sum))

    return(freq_df)
}
```

### Analysis on Tweets (Unigrams)

```{r, eval=FALSE, message=FALSE, warnings=FALSE}
#### WordCloud - disaster
disaster.data <- tweets_train %>% filter(target == 'Yes')
disaster_dtM <- preprocess_corpus(disaster.data$text)
word.freq <- sort(colSums(as.matrix(disaster_dtM)), decreasing=TRUE)
word.freq <- data.frame(word=names(word.freq), freq=word.freq)

wordcloud(words=word.freq$word, freq=word.freq$freq, min.freq = 1,
          max.words=20000, random.order=FALSE, rot.per=0.35, 
          colors=brewer.pal(8, "Dark2"))
```

```{r, eval=FALSE, message=FALSE, warnings=FALSE}
#### WordCloud - non.disaster
non.disaster.data <- tweets_train %>% filter(target == 'No')
non.disaster_dtM <- preprocess_corpus(non.disaster.data$text)
word.freq <- sort(colSums(as.matrix(non.disaster_dtM)), decreasing=TRUE)
word.freq <- data.frame(word=names(word.freq), freq=word.freq)

wordcloud(words=word.freq$word, freq=word.freq$freq, min.freq = 1,
          max.words=20000, random.order=FALSE, rot.per=0.35, 
          colors=brewer.pal(8, "Dark2"))
```

```{r, eval=FALSE, message=FALSE, warnings=FALSE}
#### Bar Plot
text_dtM <- preprocess_corpus(tweets_train$text)
text_top_n <- top_unigram(text_dtM, tweets_train$target, top_n=25)

ggplot(melt(text_top_n), aes(x=variable, y=value, fill=type)) + 
    ggtitle('Most Discriminatory Words in the Articles of News') + 
    geom_col(position='dodge') +
    labs(x='Top 25', y='Term Frequency') +
    coord_flip()
```

### Analysis on Buzzfeed news articles (Bigrams)

```{r, eval=FALSE, message=FALSE, warnings=FALSE}
text_dtM_bigram <- bigram_corpus(tweets_train$text)
text_top_n_bigram <- top_bigram(text_dtM_bigram, tweets_train$target, top_n=12)

ggplot(melt(text_top_n_bigram), aes(x=variable, y=value, fill=type)) + 
    ggtitle('Most Discriminatory Bigrams in the Articles of News') + 
    geom_col(position='dodge') +
    labs(x='Top 25', y='Term Frequency') +
    coord_flip()
```

## Model Training

### Tf-Idf function

```{r, eval=FALSE, message=FALSE, warnings=FALSE}
text_dtM <- preprocess_corpus(tweets_train$text)
tf.idf <- function(corpus){
    corpus <- Corpus(VectorSource(corpus))
    
    corpus <- tm_map(corpus, content_transformer(removeURL))
    corpus <- tm_map(corpus, content_transformer(removeUser))

    corpus <- tm_map(corpus, content_transformer(stri_trans_tolower))
    corpus <- tm_map(corpus, content_transformer(removeNumPunct))
    corpus <- tm_map(corpus, removeWords, stopwords('english'))
    corpus <- tm_map(corpus, removeSingle)
    corpus <- tm_map(corpus, stemDocument)
    corpus <- tm_map(corpus, stripWhitespace)
    
    
    dtM <- DocumentTermMatrix(corpus, 
                              control=list(weighting=function(x)
                                weightTfIdf(x, normalize=TRUE)))
    return(dtM)
}
```

### Data

```{r, eval=FALSE, message=FALSE, warnings=FALSE}
text_dtM <- preprocess_corpus(tweets_train$text)
text.tfidf <- tf.idf(tweets_train$text)

frequent_text <- findFreqTerms(text_dtM, 113)  # 30 terms
text.data <- as.matrix(text.tfidf)[, frequent_text]
label <- ifelse(tweets_train[, c('target')]=='Yes', 1, 2)

data <- data.frame(cbind(text.data, label))
data.matrix <- data[, which(names(data) != 'label')]
data.label <- data$label

train <- createDataPartition(data$label, p=.7, list=FALSE)
train_data <- data[train, ]
test_data <- data[-train, ]
```

```{r, eval=FALSE, message=FALSE, warnings=FALSE}
performance <- function(pred.prob, pred.class, method, test, positive){
  con <- confusionMatrix(pred.class,test,positive=positive)
  Sensitivity <- con$byClass[1]
  Specificity <- con$byClass[2]
  ROCit_obj <- rocit(score=pred.prob,class=test)
  AUC <- ROCit_obj$AUC
  ACC <- sum(pred.class==test)/length(test)
  
  plot(ROCit_obj);title(method)
  text(0.7,0.4,paste("AUC = ",round(AUC,3),"\n","ACC = ",round(ACC,3)),cex = 1.5)
  return(c(Sensitivity,Specificity,AUC = AUC,ACC=ACC))
}
```

### K-Means

```{r, eval=FALSE, message=FALSE, warnings=FALSE}
### Elbow Method
fviz_nbclust(data.matrix, kmeans, method = "wss") +
  geom_vline(xintercept = 4, linetype = 2) +
  labs(subtitle = "Elbow method")
```

```{r, eval=FALSE, message=FALSE, warnings=FALSE}
### Silhouette Method
fviz_nbclust(data.matrix, kmeans, method='silhouette')+
  labs(title='Silhouette Method')
```

```{r, eval=FALSE, message=FALSE, warnings=FALSE}
kmeans_classifier <- kmeans(x=data.matrix, centers=2, nstart=25)
correct.clust <- sum(data.label==kmeans_classifier$cluster)
accuracy <- max(correct.clust, nrow(data) - correct.clust) / nrow(data)
accuracy

CrossTable(kmeans_classifier$cluster, data$label,
           prop.chisq=FALSE, prop.t=FALSE, dnn=c('Predicted', 'Actual'))
```

### Gaussian Mixture Model

```{r, eval=FALSE, message=FALSE, warnings=FALSE}
library(mclust)
mm_classifier <- Mclust(data.matrix, G=2:9)

plot.Mclust(mm_classifier, what = "BIC", 
     ylim = range(mm_classifier$BIC[, ], na.rm = TRUE), 
     legendArgs = list(x = "topright", cex =0.7))
```

```{r, eval=FALSE, message=FALSE, warnings=FALSE}
library(mclust)
mm_classifier <- Mclust(data.matrix, G=2)

summary(mm_classifier)
```

```{r, eval=FALSE, message=FALSE, warnings=FALSE}
CrossTable(mm_classifier$classification, data$label,
           prop.chisq=FALSE, prop.t=FALSE, dnn=c('Predicted', 'Actual'))
```

```{r, eval=FALSE, message=FALSE, warnings=FALSE}
adjustedRandIndex(data$label, mm_classifier$classification)
```

```{r, eval=FALSE, message=FALSE, warnings=FALSE}
gmm.means <- mm_classifier$parameters$mean
gmm.sigma <- mm_classifier$parameters$variance$sigma
estimates.1 <- data.frame(text=colnames(data.matrix),
                          mean=gmm.means[, 1],
                          sigma=diag(gmm.sigma[, , 1]))
estimates.2 <- data.frame(text=colnames(data.matrix),
                          mean=gmm.means[, 2],
                          sigma=diag(gmm.sigma[, , 2]))
estimates.0 <- data.frame(text=colnames(data.matrix),
                     mean.1=gmm.means[, 1],
                     sigma.1=diag(gmm.sigma[, , 1]),
                     mean.2=gmm.means[, 2],
                     sigma.2=diag(gmm.sigma[, , 2]))
```

```{r, eval=FALSE, message=FALSE, warnings=FALSE}
ggplot(estimates.0[1:15,], aes(x=text, group=1)) + 
  geom_hline(yintercept = 0,col = 2) + 
  geom_point(aes(y=mean.1), shape=21, size=3, fill="red") +
  geom_errorbar(width=0.5, size=1,
                aes(ymin=mean.1-1.96*sigma.1, ymax=mean.1+1.96*sigma.1),
                lwd=1, color="red") +
  geom_point(aes(y=mean.2), shape=21, size=3, fill="blue") +
  geom_errorbar(width=0.2, size=1,
                aes(ymin=mean.2-1.96*sigma.2, ymax=mean.2+1.96*sigma.2),
                lwd=1, color="blue") +
  labs(title = "Gaussian Mixture Mean Estimates",y = "Estimates.Value") +
  theme(plot.title = element_text(hjust = 0.5),
        axis.text.x=element_text(size=11, angle=30))
```

```{r, eval=FALSE, message=FALSE, warnings=FALSE}
ggplot(estimates.0[16:30,], aes(x=text, group=1)) + 
  geom_hline(yintercept = 0,col = 2) + 
  geom_point(aes(y=mean.1), shape=21, size=3, fill="red") +
  geom_errorbar(width=0.5, size=1,
                aes(ymin=mean.1-1.96*sigma.1, ymax=mean.1+1.96*sigma.1),
                lwd=1, color="red") +
  geom_point(aes(y=mean.2), shape=21, size=3, fill="blue") +
  geom_errorbar(width=0.2, size=1,
                aes(ymin=mean.2-1.96*sigma.2, ymax=mean.2+1.96*sigma.2),
                lwd=1, color="blue") +
  labs(title = "Gaussian Mixture Mean Estimates",y = "Estimates.Value") +
  theme(plot.title = element_text(hjust = 0.5),
        axis.text.x=element_text(size=11, angle=30))

```

### Logistic


```{r, eval=FALSE, message=FALSE, warnings=FALSE}
fit_glm <- glm(label ~., data=train_data, family=binomial)

log_prob <- predict(fit_glm, test_data, type="response")
log_pred <- ifelse(log_prob > 0.5, 1, 0)

cat('accuracy:', mean(log_pred == test_data$label))
```

```{r, eval=FALSE, message=FALSE, warnings=FALSE}
cutpoints <- data.frame(cut=seq(0.1, 0.9, by = 0.01),ACC=0)
for(i in 1:nrow(cutpoints)){
  pred_log <- ifelse(log_prob > cutpoints$cut[i], 1, 0)
  cutpoints$ACC[i] <- mean(pred_log ==  test_data$label)
}

cut_best <- cutpoints$cut[which.max(cutpoints$ACC)]
log_pred <- ifelse(log_prob > cut_best, 1, 0)

cat('accuracy:', mean(log_pred == test_data$label))
```

```{r, eval=FALSE, message=FALSE, warnings=FALSE}
confusionMatrix(factor(log_pred), factor(test_data$label))
```

```{r, eval=FALSE, message=FALSE, warnings=FALSE}
performance(log_prob, as.factor(log_pred), 'Logistic', as.factor(test_data$label), '1')
```

### Random Forest
```{r, eval=FALSE, message=FALSE, warnings=FALSE}
train_data$label <- as.factor(train_data$label)
rf <- randomForest(label ~., data=train_data)

rf_pred <- predict(rf, newdata=test_data, type = 'class')
cat('accuracy:', mean(rf_pred == test_data$label))
```

```{r, eval=FALSE, message=FALSE, warnings=FALSE}
ntree <- which.min(rf$err.rate[, 1])
cat('best tree size:', ntree)

hyper_grid <- expand.grid(mtry = seq( 2, 16, by = 1),
                          node_size = seq(5, 17, by = 2),
                          sample_size = c(0.575, 0.635, 0.7, 0.8),
                          OOB_error = 0)

for (i in 1:nrow(hyper_grid)) {
  # train model
  model <- ranger(formula = label ~ ., data = train_data, 
                  num.trees = ntree, 
                  mtry = hyper_grid$mtry[i],
                  min.node.size = hyper_grid$node_size[i], 
                  sample.fraction = hyper_grid$sample_size[i],
                  seed = 101)
  
  hyper_grid$OOB_error[i] <- model$prediction.error
}

min_OOB_error <- hyper_grid %>% 
  dplyr::arrange(OOB_error) %>% 
  head(10)

ACC_rf <- data.frame(mtry=rep(0, 10),
                     node_size=rep(0, 10),
                     sample_size=rep(0, 10),
                     OOB_error=rep(0, 10),
                     ACC=rep(0, 10))

for (i in 1:10){
  rf_param <- min_OOB_error[i,]
  
  rf_ <- randomForest(formula=label ~., data=train_data,
                      ntree=ntree, 
                      mtry=rf_param$mtry,
                      nodesize=rf_param$node_size,
                      sampsize=ceiling(rf_param$sample_size * nrow(train_data)))
  
  rf_pred <- predict(rf_, newdata=test_data, type='class')
  acc <- mean(rf_pred==test_data$label)
  ACC_rf[i, ] <- cbind(min_OOB_error[i,], ACC=acc)
}

best_rf_param <- ACC_rf %>%
  dplyr::arrange(desc(ACC)) %>%
  head(1)
```

```{r, eval=FALSE, message=FALSE, warnings=FALSE}
rf_best <- randomForest(formula=label ~., data=train_data,
                        ntree=ntree, 
                        mtry=best_rf_param$mtry,
                        nodesize=best_rf_param$node_size,
                        sampsize=ceiling(best_rf_param$sample_size * nrow(train_data)))

rf_prob <- predict(rf_best, test_data, type='prob')[,2]
rf_pred <- ifelse(rf_prob > 0.5, 1, 0)

cat('accuracy:', mean(rf_pred == test_data$label))
```

```{r, eval=FALSE, message=FALSE, warnings=FALSE}
confusionMatrix(factor(rf_pred), factor(test_data$label))
```

```{r, eval=FALSE, message=FALSE, warnings=FALSE}
performance(rf_prob, as.factor(rf_pred), 'Random Forest', as.factor(test_data$label), "1")
```

### Latent Dirichlet Allocation 

```{r, eval=FALSE, message=FALSE, warnings=FALSE}
library(text2vec)

lda.dtM <- as(as.matrix(text_dtM), 'CsparseMatrix')

ntopics <- 3
alpha.prior <- 0.1 
beta.prior <- 0.01 
n.iter <- 1000 
conv.tol <- 0.0001 

lda_model = LDA$new(n_topics=ntopics,
                    doc_topic_prior=alpha.prior,
                    topic_word_prior=beta.prior)
doc_topic_distr =   lda_model$fit_transform(x=lda.dtM, 
                                            n_iter=n.iter,
                                            convergence_tol=cov.tol, 
                                            n_check_convergence = 25,
                                            progressbar = FALSE)

lda_model$plot()
```

## Simulation Study

### Resample Function

```{r, eval=FALSE, message=FALSE, warnings=FALSE}
resample = function(data,n){
  r = c(1:dim(data)[1])
  re = sample(r,n,replace = T)
  resam = rep()
  for(i in (1:n)){
    resam = rbind(resam,data[re[i],])
  }
return(resam)
}
```

### Bootstrap

```{r, eval=FALSE, message=FALSE, warnings=FALSE}
label <- ifelse(tweets_train[, c('target')]=='Yes', 1, 0)
log_data <- data.frame(cbind(text.data, label))
colnames(data) <- c(colnames(as.matrix(text_dtM))[1:30], 'label')   

B = 200
kmean_accuracy = rep(NaN,B)
gmm_accuracy = rep(NaN,B)
log_accuracy = rep(NaN,B)
#rf_accuracy = rep(NaN,B)
mean1_estimates = rep(NaN,length(data.matrix))
mean2_estimates = rep(NaN,length(data.matrix))
sigma1_estimates = rep(NaN,length(data.matrix))
sigma2_estimates = rep(NaN,length(data.matrix))
pro1 = rep(NaN,B)
pro2 = rep(NaN,B)
for (i in c(1:B)){
  redata = resample(data,5000)
  re_label = redata$label
  redata = redata[, which(names(redata) != 'label')]
  log_data = resample(log_data,5000)
  train <- createDataPartition(log_data$label, p=.7, list=FALSE)
  train_log <- log_data[train, ]
  test_log <- log_data[-train, ]
  
  kmeans_classifier <- kmeans(redata, centers=2, nstart=25)
  k_correct.clust <- sum(re_label==kmeans_classifier$cluster)
  kmean_accuracy[i] <- max(k_correct.clust,
                           nrow(redata) - k_correct.clust) / nrow(redata)
  
  gmm_classifier <- Mclust(redata, G=2)
  G_correct.clust <- sum(re_label==gmm_classifier$classification)
  gmm_accuracy[i] <- max(G_correct.clust,
                         nrow(redata) - G_correct.clust) / nrow(redata)
  gmm.means <- gmm_classifier$parameters$mean
  gmm.sigma <- gmm_classifier$parameters$variance$sigma
  gmm.pro = gmm_classifier$parameters$pro
  pro1[i] = max(gmm.pro)
  pro2[i] = min(gmm.pro)
  gmm_estimates <- data.frame(text=colnames(redata),
                            mean.1=gmm.means[, match(pro1[i],gmm.pro)],
                            sigma.1=diag(gmm.sigma[, , match(pro1[i],gmm.pro)]),
                            mean.2=gmm.means[, match(pro2[i],gmm.pro)],
                            sigma.2=diag(gmm.sigma[, , match(pro2[i],gmm.pro)]))
  mean1_estimates = cbind(mean1_estimates,gmm_estimates[2]) 
  mean2_estimates = cbind(mean2_estimates,gmm_estimates[4])
  sigma1_estimates = cbind(sigma1_estimates,gmm_estimates[3])
  sigma2_estimates = cbind(sigma2_estimates,gmm_estimates[5])

  fit_glm <- glm(label ~., data=train_log, family=binomial)
  log_prob <- predict(fit_glm, test_log, type="response")
  log_pred <- ifelse(log_prob > 0.5, 1, 0)
  log_accuracy[i]= mean(log_pred == test_log$label)

  }
mean1_estimates = mean1_estimates[,-(1)]
mean2_estimates = mean2_estimates[,-(1)]
sigma1_estimates = sigma1_estimates[,-(1)]
sigma2_estimates = sigma2_estimates[,-(1)]

```

### Visualization

```{r, eval=FALSE, message=FALSE, warnings=FALSE}
m1<-t(mean1_estimates)
m2<-t(mean2_estimates)
s1<-t(sigma1_estimates)
s2<-t(sigma2_estimates)

boxplot(m1[,1:15],at=seq(1,29,2),main = "Mean1 1~15",
        ylab = "Mean Estimate",col = "#6495ED",border = "#191970")
boxplot(m1[,16:30],at=seq(1,29,2),main = "Mean1 16~30",
        ylab = "Mean Estimate",col = "#6495ED",border = "#191970")
boxplot(m2[,1:15],at=seq(1,29,2),main = "Mean2 1~15",
        ylab = "Mean Estimate",col = "#D2691E",border = "#191970")
boxplot(m2[,16:30],at=seq(1,29,2),main = "Mean2 16~30",
        ylab = "Mean Estimate",col = "#D2691E",border = "#191970")
boxplot(s1[,1:15],at=seq(1,29,2),main = "Sigma1 1~15",
        ylab = "Sigma Estimate",col = "#B0C4DE",border = "#191970")
boxplot(s1[,16:30],at=seq(1,29,2),main = "Sigma1 16~30",
        ylab = "Sigma Estimate",col = "#B0C4DE",border = "#191970")
boxplot(s2[,1:15],at=seq(1,29,2),main = "Sigma2 1~15",
        ylab = "Sigma Estimate",col = "#40E0D0",border = "#191970")
boxplot(s2[,16:30],at=seq(1,29,2),main = "Sigma2 16~30",
        ylab = "Sigma Estimate",col = "#40E0D0",border = "#191970")

mean_mean1 = apply(mean1_estimates,1,mean)
mean_mean2 = apply(mean2_estimates,1,mean)
sd_mean1 = apply(sigma1_estimates,1,mean)
sd_mean2 = apply(sigma2_estimates,1,mean)

boxplot(kmean_accuracy,main = 'K-Means accuracy')
boxplot(gmm_accuracy,main = 'GMM accuracy')
boxplot(log_accuracy,main = 'Logistic accuracy')

boxplot(pro1,
        main = "Pro1",
        ylab = "Probability",
        col = "orange",
        border = "red",
        notch = TRUE
)
boxplot(pro2,
        main = "Pro2",
        ylab = "Probability",
        col = "orange",
        border = "red",
        notch = TRUE
)
boxplot(kmean_accuracy,gmm_accuracy,
        main = "Accuracy for Unsupervised",
        names = c("K-Means", "GMM"),
        ylab = "Accuracy",
        col = c("#3399FF","#9933FF"),
        border = "brown",
        notch = TRUE
)
boxplot(log_accuracy,
        main = "Accuracy for Supervised",
        xlab = "LR",
        ylab = "Accuracy",
        col = "orange",
        border = "brown",
        notch = TRUE
) 
```
